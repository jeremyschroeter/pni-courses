{"cells":[{"cell_type":"markdown","metadata":{"id":"h07cu7MfMT0D"},"source":["# Encoding models: Poisson General Linear Model (GLM)\n","\n","In this notebook, we will use a Poisson GLM to learn an encoding transformation\n","from stimulus to neural activity. In particular, we will be looking at recordings\n","from retinal ganglion cells in response to binary temporal white noise.\n","\n","The data we will be using is from [Uzzell & Chichilnisky, 2004](http://jn.physiology.org/content/92/2/780.long); see `README.txt` file in the `/data_RGCs` directory for details).\n","The dataset can be downloaded [here](https://pillowlab.princeton.edu/data/data_RGCs.zip) (FYI you probably will need to work on this notebook locally to be able to access the downloaded data).\n","\n","The dataset is provided for tutorial purposes only, and should not be\n","distributed or used for publication without express permission from EJ\n","Chichilnisky (ej@stanford.edu).\n","\n","This notebook was last updated on August 13, 2025 by Jesse Kaminsky. Previously it was made on July 27, 2023 by Iman Wahle and Yousuf El-Jayyousi,\n","adapted from a set of [notebooks](https://github.com/pillowlab/GLMspiketraintutorial_python) developed by Jesse Kaminsky and JW Pillow. I encourage you to check them out to learn more details and implement more complicated GLMs."]},{"cell_type":"markdown","metadata":{"id":"aX5ODKSaMT0E"},"source":["## 1. Load and visualize data"]},{"cell_type":"markdown","metadata":{"id":"0STcQxWrMT0E"},"source":["Our dataset includes three pieces of information:\n","\n","- `stim` : the stimulus value at each frame\n","- `stim_times` : the time in seconds at each frame (~120 Hz)\n","- `spike_times` : a list of spike times in seconds for 1 neuron\n","\n","Before beginning any analyses, let's load the data and make sure it matches\n","our expectations. In particular:\n","\n","1. check the data shapes\n","2. visualize the magnitude of the stimulus over the course of the first 1s of\n","   the trial (i.e. with `plt.plot`)\n","3. visualize neuron spike times over the course of the first\n","   1s of the trial (i.e. with `plt.stem`)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p2DmQ-BvMT0F"},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","from scipy.io import loadmat\n","from scipy.linalg import norm\n","import statsmodels.api as sm\n","from scipy.optimize import minimize\n","import seaborn as sns\n","\n","sns.set_context(\"notebook\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Hug_tA5gMT0F"},"outputs":[],"source":["# load data\n","datadir = \"data_RGCs/\"\n","stim = np.squeeze(loadmat(f\"{datadir}Stim.mat\")[\"Stim\"])\n","stim_times = np.squeeze(loadmat(f\"{datadir}stimtimes.mat\")[\"stimtimes\"])\n","spike_times = [\n","    np.squeeze(x) for x in np.squeeze(loadmat(f\"{datadir}SpTimes.mat\")[\"SpTimes\"])\n","][2]\n","dt_stim = spike_times[1] - spike_times[0]\n","nframes_to_plot = 120"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ihH73nH4MT0G"},"outputs":[],"source":["# 1. check the data shapes\n","print(\"stim shape: \", ### INSERT CODE HERE)\n","print(\"stim_times shape: \", ### INSERT CODE HERE)\n","print(\"spike_times shape: \", ### INSERT CODE HERE)\n","print(\"dt: \", dt_stim)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c40XLveAMT0H"},"outputs":[],"source":["# 2. visualize the magnitude of the stimulus over the course of the first 1s of\n","#    the trial (i.e. with `plt.plot`)\n","\n","fig, ax = plt.subplots(2, 1, figsize=(10, 6), sharex=True)\n","### INSERT CODE HERE\n","\n","\n","# 3. visualize neuron 2's (zero-indexed) spike times over the course of the\n","#    first 1s of the trial (i.e. with `plt.stem`)\n","\n","# get the spike times that fall within the first 1s\n","spike_times_1s = ### INSERT CODE HERE\n","\n","# plot a dash every time there is a spike\n","### INSERT CODE HERE"]},{"cell_type":"markdown","metadata":{"id":"Q0qawG0YMT0H"},"source":["## 2. Format data for analysis"]},{"cell_type":"markdown","metadata":{"id":"vkEHT-StMT0I"},"source":["In order to map stimulus to neuron responses, we need to compute the number\n","of spikes that occur during each frame of the stimulus. To do this, find\n","the time window associated with each stimulus frame and add up the number of\n","spikes that occur within that time window for each neuron.\n","\n","One way to do this is to compute the time at the center of each time window\n","and pass this along with the spike times to `np.histogram`."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mLIDyXa3MT0I"},"outputs":[],"source":["# compute spike counts per time bin\n","### INSERT CODE HERE\n","spike_counts =\n","\n","# plot the spike counts over the first 1s of the trial\n","plt.figure(figsize=(10, 3))\n","plt.stem(stim_times[:nframes_to_plot], spike_counts[:nframes_to_plot], basefmt=\"gray\")\n","plt.title(\"binned spike counts\")\n","plt.ylabel(\"spike count\")\n","plt.xlabel(\"time (s)\")\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"06df-EbTMT0I"},"source":["Next, we need to construct a design matrix, or a matrix that includes all\n","regressors we want to include in our model. In our case, stimuli from previous\n","time points may be important to present spiking activity, so we will include\n","time-lagged stimuli as individual regressors.\n","\n","Construct a design matrix with 25 time lags, each shifted over by 1 frame.\n","This should result in an n_samples x 25 matrix. Pad early samples with zeros\n","if the lagged frames extend beyond the samples we have.\n","\n","This can either be constructed using a for loop, or with `scipy.linalg.hankel`."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fNT09hKXMT0I"},"outputs":[],"source":["nlags = 25\n","\n","# Create design matrix containing time-lagged stimuli. It should be of dimension (n_samples X 25)\n","\n","### INSERT CODE HERE\n","design_mat =\n","\n","# Let's visualize a small part of the design matrix just to see it\n","plt.figure(figsize=[10, 8])\n","plt.imshow(design_mat[:50], aspect=\"auto\", interpolation=\"nearest\")\n","plt.xticks(np.arange(nlags)[::5], np.arange(nlags)[::5] - nlags + 1)\n","plt.xlabel(\"lags before spike time\")\n","plt.ylabel(\"sample\")\n","plt.colorbar()\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"JMv_Yv4EMT0J"},"source":["## 3. Compute and visualize the spike-triggered average (STA)"]},{"cell_type":"markdown","metadata":{"id":"s12zxVCmMT0J"},"source":["When the stimulus is Gaussian white noise, the STA provides an unbiased\n","estimator for the filter in a GLM. In many cases it's useful to visualize the STA (even if your stimuli are\n","not white noise), just because if we don't see any kind of structure then\n","this may indicate that we have a problem (e.g., a mismatch between the\n","design matrix and binned spike counts."]},{"cell_type":"markdown","metadata":{"id":"T4cQV_C4MT0J"},"source":["The spike-triggered average is the average stimulus presented relative to the\n","time of a spike. In our case, since we are interested in how visual stimuli\n","is encoded in retinal ganglion cells, we are specifically interested in what\n","the stimulus looks like during the time leading up to the time of a spike (as\n","opposed to post-spike). Since our design matrix already staggers the stimulus\n","by time, multiplying this matrix by our binned spike counts will give a\n","weighted sum of presented stimuli before and during spike time. Dividing this\n","product by the total number of spikes will give the average. Compute this\n","average below and plot it as a function of time before spike."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zea6Mn2DMT0J"},"outputs":[],"source":["# Compute the spike triggered average (you can do this in one line)\n","# what size do you think it should be?\n","sta = ### INSERT CODE HERE\n","\n","### Plot it\n","sta_times = np.arange(-nlags + 1, 1) * dt_stim  # time bins for STA (in seconds)\n","plt.figure(figsize=(10, 3))\n","plt.plot(sta_times, sta)\n","# plt.scatter(sta_times, sta, marker='o', color='r', s=20)\n","plt.xlabel(\"time before spike (s)\")\n","plt.ylabel(\"STA\")\n","\n","# If you're still using cell #1, this should look like a biphasic filter\n","# with a negative lobe just prior to the spike time."]},{"cell_type":"markdown","metadata":{"id":"H1jSWpucMT0K"},"source":["## 4. Add an offset term"]},{"cell_type":"markdown","metadata":{"id":"JF3Hg_zHMT0K"},"source":["So far, we have built a design matrix that will allow us to learn a weight\n","corresponding to the stimulus at each lagged time point leading up to our\n","neuron's response. However, we also need to include an offset term that allows\n","our model to learn a fit that doesn't necessarily go through the origin.\n","(Remember $y = mx + b$ from high school? What happens if we reduce this model\n","to only be $y = mx$? What solutions are we limited to?)\n","\n","To allow our model to learn an offset term, add a column of ones to the\n","beginning of the design matrix using `np.hstack`."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JH4MhdBGMT0K"},"outputs":[],"source":["### INSERT CODE HERE\n","print(design_mat.shape)"]},{"cell_type":"markdown","metadata":{"id":"xxdpooiVMT0K"},"source":["## 5. Define the log-likelihood for the Poisson GLM model"]},{"cell_type":"markdown","metadata":{"id":"YJvIeEF6MT0L"},"source":["For a given (stimulus, spike count) sample $(x_i,y_i)$, we want to define our\n","model as $ y_i \\sim ~ \\text{Poission}(\\lambda)$, where $\\lambda = \\text{exp}(x_i\\theta)$.\n","\n","Our goal is to learn the value of $\\theta$ for which the likelihood of seeing\n","our observed data $P(y_i | x_i, \\theta)$ is maximized. The likelihood for a\n","Poission distribution is proportional to $\\lambda^y\\text{exp}(-\\lambda)$. Substituting\n","in our equation for $\\lambda$, our optimization problem for a single sample\n","becomes:\n","$\\theta_{\\text{opt}} = \\text{argmax}_{\\theta} [\\text{exp}(x_i\\theta)^{y_i}\\text{exp}(\\text{exp}(x_i\\theta))]$.\n","\n","Since we want the $\\theta$ that best fits our entire set of samples, we want to\n","take the product of the above likelihood across all $i$, or equivalently the\n","sum of the log-likelihoods:\n","$\\theta_{\\text{opt}} = \\text{argmax}_{\\theta} [\\sum_{i} [y_ix_i\\theta - \\text{exp}(x_i\\theta)]]$.\n","\n","Implement this computation of the log-likelihood below for a given value\n","of $\\theta$. Note that in the next step, we will be using an optimization method\n","that minimizes a likelihood function (as opposed to maximizing), so we will\n","actually want to take negative of the value above as our return value.\n","\n","Be careful to use the proper operators for matrix vs element-wise multiplication."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"a_OtscoUMT0L"},"outputs":[],"source":["def neg_log_likelihood(theta, X, Y):\n","     return ### INSERT CODE HERE"]},{"cell_type":"markdown","metadata":{"id":"BDaOslgZMT0L"},"source":["## 6. Find the optimal $\\theta$"]},{"cell_type":"markdown","metadata":{"id":"XObberlOMT0L"},"source":["Now that we have defined our negative log likelihood function, we want to find\n","the value of $\\theta$ that minimizes this function given the data we observe.\n","Use the function `minimize` from `scipy.optimize` to find the optimal value\n","of $\\theta$."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rRNvLTTYMT0L"},"outputs":[],"source":["theta_init = np.random.randn(26)\n","theta_opt = ### INSERT CODE HERE\n","print(theta_opt)"]},{"cell_type":"markdown","metadata":{"id":"cqXOUMadMT0L"},"source":["## 7. Predict with learned values of $\\theta$"]},{"cell_type":"markdown","metadata":{"id":"nSK-sDLdMT0M"},"source":["Use the optimal value of $\\theta$ found above to predict from the design matrix\n","what spike counts we should observe."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"N3WCY6JMMT0M"},"outputs":[],"source":["spike_counts_pred = ### INSERT CODE HERE"]},{"cell_type":"markdown","metadata":{"id":"irJozEIoMT0M"},"source":["Plot these predictions over the observed data that you plotted in step 2."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"u6gSNF2jMT0M"},"outputs":[],"source":["# plot the spike counts over the first 1s of the trial\n","### INSERT CODE HERE"]},{"cell_type":"markdown","metadata":{"id":"eJOJan7VMT0M"},"source":["Plot the optimal value of $\\theta$ that you found over the STA that you\n","plotted in step 3. Note that $\\theta$ is a vector - make sure to only plot\n","the entries in this vector that make sense to compare to the STA.\n","Additionally, since we are comparing two distinct quantities, normalize both\n","$\\theta_{\\text{opt}}$ and the STA so that we can just compare their shapes.\n","\n","What do you observe? Does this comparison make sense?"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UhHCyxAjMT0M"},"outputs":[],"source":["sta_times = ### INSERT CODE HERE\n","### INSERT CODE HERE\n","plt.xlabel(\"time before spike (s)\")\n","plt.ylabel(\"arbitrary units\")\n","plt.title(\"(Normalized) STA and GLM filter (theta_opt)\")\n","plt.legend()"]},{"cell_type":"markdown","metadata":{"id":"kB1dSluzMT0M"},"source":["## 8. Use statsmodels package instead"]},{"cell_type":"markdown","metadata":{"id":"wDxeaGyQMT0N"},"source":["While in the previous steps you constructed a log-likelihood function by hand\n","to optimize with respect to, the package `statsmodels` has built-in model types\n","for which it will perform this optimization automatically. Review the example\n","below to see how you can use `statsmodels` to perform the same analysis as\n","above more succinctly and verify that your results match those from this\n","implementation."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rlvKSdJ8MT0N"},"outputs":[],"source":["glm_poisson_exp = sm.GLM(\n","    endog=spike_counts, exog=design_mat, family=sm.families.Poisson()\n",")\n","pGLM_results = glm_poisson_exp.fit(max_iter=100, tol=1e-6, tol_criterion=\"params\")\n","spike_counts_pred = np.exp(design_mat @ pGLM_results.params)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MjLhbfc9MT0N"},"outputs":[],"source":["# plot the spike counts over the first 1s of the trial\n","plt.figure(figsize=(10, 3))\n","plt.stem(stim_times[:nframes_to_plot], spike_counts[:nframes_to_plot], basefmt=\"gray\")\n","plt.plot(\n","    stim_times[:nframes_to_plot], spike_counts_pred[:nframes_to_plot], color=\"green\"\n",")\n","plt.title(\"binned spike counts\")\n","plt.ylabel(\"spike count\")\n","plt.xlabel(\"time (s)\")\n","plt.legend([\"predicted\", \"actual\"])\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oSXZLL1WMT0N"},"outputs":[],"source":["sta_times = np.arange(-nlags + 1, 1) * dt_stim  # time bins for STA (in seconds)\n","plt.figure(figsize=(10, 3))\n","plt.plot(sta_times, sta / norm(sta), label=\"STA\")\n","plt.plot(\n","    sta_times,\n","    pGLM_results.params[1:] / norm(pGLM_results.params[1:]),\n","    label=\"theta_opt\",\n",")\n","plt.xlabel(\"time before spike (s)\")\n","plt.ylabel(\"arbitrary units\")\n","plt.title(\"(Normalized) STA and GLM filter (theta_opt)\")\n","plt.legend()"]},{"cell_type":"code","source":[],"metadata":{"id":"eRUmbE9YO5y5"},"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"cd_env","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.16"},"orig_nbformat":4,"colab":{"provenance":[{"file_id":"19-YSrcIWFoLPM_RuVezPtSRWFcn8JQ3C","timestamp":1753444279015},{"file_id":"1abJKrdqX6BY3Dm8_35jEGwF4hAxc1A7D","timestamp":1724014288880}]}},"nbformat":4,"nbformat_minor":0}